{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Resize\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import display_denoising_images\n",
    "from training_functions import train_denoising_model, validate_model\n",
    "from autoencoders import Autoencoder1, Autoencoder2, Autoencoder3\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from custom_dataset import CustomImageDataset\n",
    "from noise import apply_scanning_artifacts\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Set environment variables\n",
    "TRAIN_FUNCTION = train_denoising_model\n",
    "MODEL = Autoencoder3()\n",
    "EPOCHS = 20\n",
    "DEVICE = \"mps\"  # Replace with \"cuda\" if you have a GPU\n",
    "NOISE_PARAMS = {\n",
    "    \"noise\": 0.075,\n",
    "    \"warp\": 0.5,\n",
    "    \"speckle\": 0.4,\n",
    "    \"streak\": 0.4,\n",
    "    \"rotate\": 0.1\n",
    "}\n",
    "\n",
    "image_dataset_path = \"/Users/leo/Programming/autoencoder/data/TextImages/train_cleaned\"\n",
    "transform = transforms.Compose([\n",
    "    Resize((256, 256)),  # Resize all images to 224x224\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "full_dataset = CustomImageDataset(image_dataset_path, transform=transform)\n",
    "\n",
    "# Splitting and DataLoader remains the same...\n",
    "train_size = int(0.75 * len(full_dataset))\n",
    "valid_size = len(full_dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(full_dataset, [train_size, valid_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Get some validation images\n",
    "valid_dataiter = iter(valid_loader)\n",
    "first_n_valid_images, _ = next(valid_dataiter)\n",
    "first_n_valid_images = first_n_valid_images[:10]\n",
    "input_dim = first_n_valid_images.shape[-1] * first_n_valid_images.shape[-2] * first_n_valid_images.shape[-3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/leo/Programming/autoencoder/main.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train_losses, valid_losses \u001b[39m=\u001b[39m [], []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train_denoising_model(MODEL, train_loader, optimizer, criterion, DEVICE, apply_scanning_artifacts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mNOISE_PARAMS)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     valid_loss \u001b[39m=\u001b[39m validate_model(MODEL, valid_loader, DEVICE, apply_scanning_artifacts, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mNOISE_PARAMS)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m~/Programming/autoencoder/training_functions.py:18\u001b[0m, in \u001b[0;36mtrain_denoising_model\u001b[0;34m(model, data_loader, optimizer, criterion, device, apply_noise_func, **noise_params)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m apply_noise_func:\n\u001b[1;32m     16\u001b[0m     \u001b[39m# Convert tensor to numpy, apply noise, and convert back to tensor\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     data_np \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     noisy_data_np \u001b[39m=\u001b[39m [apply_noise_func(img, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnoise_params) \u001b[39mfor\u001b[39;49;00m img \u001b[39min\u001b[39;49;00m data_np]\n\u001b[1;32m     19\u001b[0m     noisy_data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39marray(noisy_data_np)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     20\u001b[0m     noisy_data \u001b[39m=\u001b[39m noisy_data\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Programming/autoencoder/training_functions.py:18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m apply_noise_func:\n\u001b[1;32m     16\u001b[0m     \u001b[39m# Convert tensor to numpy, apply noise, and convert back to tensor\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     data_np \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     noisy_data_np \u001b[39m=\u001b[39m [apply_noise_func(img, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnoise_params) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m data_np]\n\u001b[1;32m     19\u001b[0m     noisy_data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39marray(noisy_data_np)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     20\u001b[0m     noisy_data \u001b[39m=\u001b[39m noisy_data\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Programming/autoencoder/noise.py:94\u001b[0m, in \u001b[0;36mapply_scanning_artifacts\u001b[0;34m(data, noise, warp, speckle, streak, rotate)\u001b[0m\n\u001b[1;32m     90\u001b[0m     was_tensor \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m# Assuming data is now in the form of a numpy array in BCHW format\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39m# Convert to HWC format for processing\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m data_np \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mtranspose(\u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m1\u001b[39;49m) \u001b[39m*\u001b[39m \u001b[39m255.0\u001b[39m\n\u001b[1;32m     96\u001b[0m processed_images \u001b[39m=\u001b[39m []\n\u001b[1;32m     97\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m data_np:\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "# Simplify the model and training setup\n",
    "MODEL = Autoencoder3().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(MODEL.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss().to(DEVICE)\n",
    "\n",
    "# Train the model\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_denoising_model(MODEL, train_loader, optimizer, criterion, DEVICE, apply_scanning_artifacts, **NOISE_PARAMS)\n",
    "    valid_loss = validate_model(MODEL, valid_loader, DEVICE, apply_scanning_artifacts, **NOISE_PARAMS)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Display images\n",
    "    display_denoising_images(\n",
    "        4,\n",
    "        first_n_valid_images,\n",
    "        MODEL,\n",
    "        DEVICE,\n",
    "        apply_scanning_artifacts,\n",
    "        **NOISE_PARAMS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
