{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Resize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/leo/Programming/autoencoder/main.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m NOISE_FACTOR \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m DATASET_PATH \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Users/leo/Programming/autoencoder/data/TextImages/train_cleaned\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     Resize((\u001b[39m256\u001b[39m, \u001b[39m256\u001b[39m)),  \u001b[39m# Resize all images to 224x224\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     transforms\u001b[39m.\u001b[39mToTensor()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m full_dataset \u001b[39m=\u001b[39m CustomImageDataset(DATASET_PATH, transform\u001b[39m=\u001b[39mtransform)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/Programming/autoencoder/main.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Split dataset into train and validation sets\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Resize' is not defined"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from custom_dataset import CustomImageDataset\n",
    "from training_functions import train_denoising_model, validate_model\n",
    "from torchvision.transforms import Resize\n",
    "from autoencoders import Autoencoder1\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Set environment variables\n",
    "TRAIN_FUNCTION = train_denoising_model\n",
    "MODEL = Autoencoder1\n",
    "EPOCHS = 2\n",
    "DEVICE = \"cpu\"\n",
    "NOISE_FACTOR = 0.1\n",
    "DATASET_PATH = \"/Users/leo/Programming/autoencoder/data/TextImages/train_cleaned\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    Resize((256, 256)),  # Resize all images to 224x224\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "full_dataset = CustomImageDataset(DATASET_PATH, transform=transform)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(0.75 * len(full_dataset))\n",
    "valid_size = len(full_dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(full_dataset, [train_size, valid_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "model = MODEL().to(DEVICE)\n",
    "criterion = nn.MSELoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and Validation\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    # Training\n",
    "    train_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), desc=\"Processing\", total=len(train_loader), leave=True)  # tqdm for batches\n",
    "    for batch_idx, (data, _) in pbar:\n",
    "        loss = TRAIN_FUNCTION(model, data, NOISE_FACTOR, optimizer, criterion, DEVICE)\n",
    "        train_loss += loss\n",
    "        pbar.set_postfix({'Batch Train Loss': f\"{loss:.4f}\"})\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    valid_loss = validate_model(model, valid_loader, device=DEVICE)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Average Train Loss: {avg_train_loss:.4f}, Average Validation Loss: {valid_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Resize\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import display_denoising_images\n",
    "from training_functions import train_denoising_model, validate_model\n",
    "from autoencoders import Autoencoder1, Autoencoder2, Autoencoder3\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from custom_dataset import CustomImageDataset\n",
    "from noise import apply_scanning_artifacts\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Set environment variables\n",
    "TRAIN_FUNCTION = train_denoising_model\n",
    "MODEL = Autoencoder3()\n",
    "EPOCHS = 20\n",
    "DEVICE = \"mps\"  # Replace with \"cuda\" if you have a GPU\n",
    "NOISE_PARAMS = {\n",
    "    \"noise\": 0.075,\n",
    "    \"warp\": 0.5,\n",
    "    \"speckle\": 0.4,\n",
    "    \"streak\": 0.4,\n",
    "    \"rotate\": 0.1\n",
    "}\n",
    "\n",
    "image_dataset_path = \"/Users/leo/Programming/autoencoder/data/TextImages/train_cleaned\"\n",
    "transform = transforms.Compose([\n",
    "    Resize((256, 256)),  # Resize all images to 224x224\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "full_dataset = CustomImageDataset(image_dataset_path, transform=transform)\n",
    "\n",
    "# Splitting and DataLoader remains the same...\n",
    "train_size = int(0.75 * len(full_dataset))\n",
    "valid_size = len(full_dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(full_dataset, [train_size, valid_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Get some validation images\n",
    "valid_dataiter = iter(valid_loader)\n",
    "first_n_valid_images, _ = next(valid_dataiter)\n",
    "first_n_valid_images = first_n_valid_images[:10]\n",
    "input_dim = first_n_valid_images.shape[-1] * first_n_valid_images.shape[-2] * first_n_valid_images.shape[-3]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
